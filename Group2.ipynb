{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN:\n",
    "    w_l_ij= None\n",
    "    b_l_j = None\n",
    "    a_l_ij = None\n",
    "    delta_l_ij = None\n",
    "    input_featureCount = None\n",
    "    input_count = None\n",
    "    layer_info = None\n",
    "    dl_dw = None\n",
    "    def __init__(self,xShape,rseed = 10,listLayer= None):\n",
    "        np.random.seed(rseed)\n",
    "        inputCount,inputDim = xShape\n",
    "        self.input_featureCount = inputDim\n",
    "        self.input_count = inputCount\n",
    "        self.layer_info = [['None',inputDim]]\n",
    "        self.w_l_ij = ['None']\n",
    "        self.b_l_j = ['None']\n",
    "        self.optimizer = None\n",
    "\n",
    "    def compile(self,optimizer,lossFunction):\n",
    "        self.optimizer = optimizer\n",
    "        self.layer_info.append(['Loss',lossFunction])\n",
    "\n",
    "    def __str__(self):\n",
    "        return\n",
    "\n",
    "    def addLayers_Dense(self,neuronCount,activationFunction):\n",
    "        if(len(self.layer_info) == 1) :\n",
    "            self.layer_info.append(['Dense',activationFunction,neuronCount])\n",
    "            w = np.random.rand(self.input_featureCount,neuronCount)\n",
    "            b = np.random.rand(1,neuronCount)\n",
    "            self.w_l_ij.append(w)\n",
    "            self.b_l_j.append(b)\n",
    "        else:\n",
    "            self.layer_info.append(['Dense',activationFunction,neuronCount])\n",
    "            w = np.random.rand(self.layer_info[-2][2],neuronCount)\n",
    "            b = np.random.rand(1,neuronCount)\n",
    "            self.w_l_ij.append(w)\n",
    "            self.b_l_j.append(b)\n",
    "\n",
    "    def forward_layer_dense(self,layerNo):\n",
    "        if layerNo < 1:\n",
    "            print(\"ERRRROR\")\n",
    "        output = self.layer_info[layerNo][1](self.a_l_ij[layerNo-1] @ self.w_l_ij[layerNo] + self.b_l_j[layerNo]) \n",
    "        self.a_l_ij.append(output)\n",
    "\n",
    "    def forward_layer_loss(self,layerNo,y):\n",
    "        y_hat  =  self.a_l_ij[-1]\n",
    "        lossFunction = self.layer_info[layerNo][1]\n",
    "        return lossFunction(y_hat,y)\n",
    "\n",
    "    def forwardProp(self,x,y):\n",
    "        self.a_l_ij = []\n",
    "        self.a_l_ij.append(x)\n",
    "        for layerNo in range(len(self.layer_info)):\n",
    "            if self.layer_info[layerNo][0] == 'Dense':\n",
    "                self.forward_layer_dense(layerNo)\n",
    "            if self.layer_info[layerNo][0] == 'Loss':\n",
    "                cost = self.forward_layer_loss(layerNo,y)\n",
    "                return cost\n",
    "            \n",
    "    def backwardProp(self,y):\n",
    "        self.dl_dw = []\n",
    "        lastIndex = len(self.layer_info) - 2\n",
    "        self.delta_l_ij = [i for i in range(0,lastIndex+1)]\n",
    "        self.delta_l_ij[lastIndex] = (2 * (self.a_l_ij[lastIndex] - y).T * self.diff_activation_linear(self.a_l_ij[lastIndex]))\n",
    "        for layerNo in range(lastIndex,0,-1):\n",
    "            self.dl_dw.append(self.a_l_ij[layerNo-1].T @ self.delta_l_ij[layerNo])\n",
    "            self.delta_l_ij[layerNo-1] = (self.w_l_ij[layerNo] @self.delta_l_ij[layerNo].T).T * self.diff_activation_linear(self.a_l_ij[layerNo-1])\n",
    "        self.dl_dw.append(['None'])\n",
    "        self.dl_dw.reverse()\n",
    "\n",
    "    def fit(self,x,y):\n",
    "        #Hyperparameters if required: \n",
    "        epoch = 21\n",
    "        eta = 1e-4\n",
    "        self.optimizer(self,x,y,eta,epoch)\n",
    "\n",
    "    @staticmethod    \n",
    "    def optimizer_gradientDescent(Obj,x,y,eta,epoch):\n",
    "        for i in  range(epoch):\n",
    "            errorSum = 0\n",
    "            print(\"Epoch:\",i,end=\"\\t\")\n",
    "            for j in range(y.shape[1]):\n",
    "                #x and y both are 2d matrix\n",
    "                x_1xd = x[j:j+1]\n",
    "                y_1xk = y[j:j+1]\n",
    "                errorSum += Obj.forwardProp(x_1xd,y_1xk)\n",
    "                Obj.backwardProp(y_1xk)\n",
    "                for index in range(1,len(Obj.w_l_ij)):\n",
    "                    Obj.w_l_ij[index] = Obj.w_l_ij[index] - (eta * Obj.dl_dw[index])\n",
    "                    Obj.b_l_j[index] = Obj.b_l_j[index] - (eta * Obj.delta_l_ij[index])\n",
    "            print(\"Error:\",errorSum)\n",
    "\n",
    "    @staticmethod\n",
    "    def loss_MSE(P,y):\n",
    "        return np.sum((P - y)**2)   \n",
    "      \n",
    "    @staticmethod\n",
    "    def activation_linear(z):\n",
    "        return z\n",
    "\n",
    "    def diff_activation_linear(self,x):\n",
    "        return np.ones(x.shape)\n",
    "    \n",
    "    @staticmethod\n",
    "    def activation_sigmoid(z):    \n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    @staticmethod\n",
    "    def activation_tanh(z):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def activation_relu(z):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def activation_softmax(z):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.datasets as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictt = sk.fetch_california_housing()\n",
    "# x = dictt.data\n",
    "# y = np.array([dictt.target])\n",
    "# y = y.T\n",
    "# x[0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2,3,4,5],[6,7,8,9,10]])\n",
    "y = np.array([[1],[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANN(x.shape,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.addLayers_Dense(3,ANN.activation_linear)\n",
    "model.addLayers_Dense(4,ANN.activation_linear)\n",
    "model.addLayers_Dense(1,ANN.activation_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(ANN.optimizer_gradientDescent,ANN.loss_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['None', 5],\n",
       " ['Dense', <function __main__.ANN.activation_linear(z)>, 3],\n",
       " ['Dense', <function __main__.ANN.activation_linear(z)>, 4],\n",
       " ['Dense', <function __main__.ANN.activation_linear(z)>, 1],\n",
       " ['Loss', <function __main__.ANN.loss_MSE(P, y)>]]"
      ]
     },
     "execution_count": 1123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delta_l_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['None',\n",
       " array([[0.03666431, 0.11669374, 0.7512807 ]]),\n",
       " array([[0.67941112, 0.65078591, 0.26879524, 0.06732467]]),\n",
       " array([[0.26362883]])]"
      ]
     },
     "execution_count": 1125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.b_l_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.dl_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.a_l_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "w_old = copy.deepcopy(model.w_l_ij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tError: 1044.8028100300546\n",
      "Epoch: 1\tError: 514.711385006634\n",
      "Epoch: 2\tError: 306.3701947013887\n",
      "Epoch: 3\tError: 198.3185123751238\n",
      "Epoch: 4\tError: 134.56775022710355\n",
      "Epoch: 5\tError: 94.0373777500907\n",
      "Epoch: 6\tError: 67.01053681329807\n",
      "Epoch: 7\tError: 48.39892446403348\n",
      "Epoch: 8\tError: 35.29134955181806\n",
      "Epoch: 9\tError: 25.9110220086745\n",
      "Epoch: 10\tError: 19.1196594922008\n",
      "Epoch: 11\tError: 14.160667607998343\n",
      "Epoch: 12\tError: 10.516787728185248\n",
      "Epoch: 13\tError: 7.826678387690066\n",
      "Epoch: 14\tError: 5.83371694187931\n",
      "Epoch: 15\tError: 4.353338256947902\n",
      "Epoch: 16\tError: 3.2515177010257856\n",
      "Epoch: 17\tError: 2.4302146223598418\n",
      "Epoch: 18\tError: 1.8173091128599674\n",
      "Epoch: 19\tError: 1.3595225708357563\n",
      "Epoch: 20\tError: 1.0173675744844826\n"
     ]
    }
   ],
   "source": [
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_new = model.w_l_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['None',\n",
       "  array([[0.5881308 , 0.89771373, 0.89153073],\n",
       "         [0.81583748, 0.03588959, 0.69175758],\n",
       "         [0.37868094, 0.51851095, 0.65795147],\n",
       "         [0.19385022, 0.2723164 , 0.71860593],\n",
       "         [0.78300361, 0.85032764, 0.77524489]]),\n",
       "  array([[0.23921822, 0.25480601, 0.85762553, 0.94977903],\n",
       "         [0.56168686, 0.17878052, 0.77025193, 0.49238104],\n",
       "         [0.63125307, 0.83949792, 0.4610394 , 0.49794007]]),\n",
       "  array([[0.77144514],\n",
       "         [0.48098413],\n",
       "         [0.32920641],\n",
       "         [0.51064106]])],\n",
       " ['None',\n",
       "  array([[0.57218926, 0.88073125, 0.86846012],\n",
       "         [0.7839544 , 0.00192464, 0.64561636],\n",
       "         [0.33085633, 0.46756353, 0.58873963],\n",
       "         [0.13008407, 0.20438651, 0.62632349],\n",
       "         [0.70329592, 0.76541527, 0.65989183]]),\n",
       "  array([[0.09593223, 0.18155081, 0.83697849, 0.88036705],\n",
       "         [0.42025752, 0.10644068, 0.74978754, 0.42381524],\n",
       "         [0.42142828, 0.73227034, 0.43091972, 0.39636726]]),\n",
       "  array([[ 0.40842161],\n",
       "         [ 0.10173592],\n",
       "         [-0.20970384],\n",
       "         [ 0.02941978]])])"
      ]
     },
     "execution_count": 1131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_old,w_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_331",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
